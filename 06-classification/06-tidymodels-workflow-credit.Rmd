---
title: "Classifying Credit Default"
subtitle: "A Tidymodels Workflow"
author: "Itamar Caspi"
date: '(updated: `r Sys.Date()`)'
output:
  html_document:
    code_folding: show
    highlight: haddock
    keep_md: no
    theme: journal
    toc: yes
    toc_depth: 4
    toc_float: yes
---

# Load packages

Load packages
```{r pacman, message=FALSE, warning=FALSE, eval=TRUE}
if (!require("pacman")) install.packages("pacman")

pacman::p_load(
  tidyverse,   # for data wrangling and visualization
  tidymodels,  # for data modeling
  vip,         # for variable importance
  here         # for referencing files and folders
)
```

and set seed for replication
```{r}
set.seed(1203)
```

# Read

```{r read_data}
credit_raw <- here("06-classification/data", "credit.csv") %>% 
  read_csv()
```


# Preprocessing

Create some "interesting" variables by re-leveling the credit history and checking account status
```{r preprocess}

credit_processed <- credit_raw %>%
  rename(default = Default) %>% 
  mutate(default = as_factor(default)) %>% 
  mutate(history = fct_collapse(history,
    good     = c("A30", "A31"),
    poor     = c("A32", "A33"),
    terrible = c("A34")
  )) %>%
  mutate(foreign = fct_recode(foreign,
    "foreign" = "A201",
    "german"  = "A202"
  )) %>%
  mutate(purpose = fct_collapse(purpose,
    newcar       = c("A40"),
    usedcar      = c("A41"),
    goods_repair = c("A42", "A43", "A44", "A45"),
    edu          = c("A46", "A48"),
    na           = c("A47"),
    biz          = c("A49", "A410")
  )) %>% 
  mutate(rent = factor(housing == "A151"))
```

Our analysis focuses on a subset of nine variables
```{r select}
credit <- credit_processed %>% 
  select(default, duration, amount,
         installment, age, history,
         purpose, foreign, rent)
```


# Split

Train-test split
```{r}
credit_split <- credit       %>% initial_split(prop = 0.5)
credit_train <- credit_split %>% training()
credit_test  <- credit_split %>% testing()
```

Cross-validation splits
```{r}
credit_folds <- credit_train %>% vfold_cv(v = 5, strata = default)
```

# Build a Model

```{r}
logit_model <- 
  logistic_reg() %>%
  set_engine("glmnet") %>% 
  set_mode("classification") %>%
  set_args(penalty = tune(), mixture = 1)
```

# Create the Recipe

```{r}
credit_rec <- 
  recipe(default ~ ., data = credit_train) %>% 
  step_dummy(all_nominal(), -default, one_hot = TRUE) %>% 
  step_interact(~ all_predictors():all_predictors()) %>%
  step_normalize(all_predictors()) %>% 
  step_zv(all_predictors()) 
```


# Create the Workflow

```{r}
logit_wfl <- 
  workflow() %>% 
  add_recipe(credit_rec) %>% 
  add_model(logit_model)
```

# Train and Tune the Model

```{r}
roc_only <- metric_set(roc_auc)

logit_result <- 
  logit_wfl %>% 
  tune_grid(
    resamples = credit_folds,
    control = control_grid(save_pred = TRUE),
    metrics = roc_only
  )
```

# Plot Cross-validation results
```{r}
logit_result %>% 
  collect_metrics() %>% 
  ggplot(aes(x = penalty, y = mean)) + 
  geom_point() + 
  geom_line() + 
  ylab("Area under the ROC Curve") +
  scale_x_log10(labels = scales::label_number())

```


show best results
```{r}
logit_result %>% 
  show_best(metric = "roc_auc", n = 5)
```

## Set best lambda

Two options: lambda that minimizes `roc_auc`, and the 1 standard error rule of thumb:
```{r}
lambda_min <- logit_result %>% 
  select_best(
    metric = "roc_auc"
  )

lambda_1se <- logit_result %>% 
  select_by_one_std_err(
    metric = "roc_auc",
    desc(penalty)
  ) %>% 
  select(penalty)
```

## Last fit

Final workflow
```{r}
logit_wfl_final <- 
  logit_wfl %>%
  finalize_workflow(lambda_1se)
```

Last fit on the test set
```{r}
logit_last_fit <- 
  logit_wfl_final %>% 
  last_fit(credit_split)
```

# Variable importance
```{r}
logit_last_fit %>% 
  pluck(".workflow", 1) %>%   
  pull_workflow_fit() %>% 
  vip(num_features = 10)
```

# ROC AUC on the train and test sets

```{r}
logit_wfl_final %>%
  fit(data = credit_train) %>% 
  predict(new_data = credit_train, type = "prob") %>% 
  roc_curve(credit_train$default, .pred_0) %>% 
  autoplot() +
  labs(title = "Training set AUC")
```

```{r}
logit_last_fit %>% 
  collect_predictions() %>% 
  roc_curve(default, .pred_0) %>% 
  autoplot() +
  labs(title = "Test set AUC")
```

```{r}
logit_last_fit %>% 
  collect_metrics() %>% 
  filter(.metric == "roc_auc")
```


